{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "customizing_adanet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qdOigM89PNgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14436
        },
        "outputId": "66d06458-eebd-4e7f-91ef-870d2b4b046b"
      },
      "cell_type": "code",
      "source": [
        "# Install bazel\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.19.0/bazel-0.19.0-installer-linux-x86_64.sh \\\n",
        "  && chmod +x bazel-0.19.0-installer-linux-x86_64.sh \\\n",
        "  && ./bazel-0.19.0-installer-linux-x86_64.sh --user \\\n",
        "  && ln -sf $HOME/bin/bazel /usr/local/bin/bazel\n",
        "\n",
        "# Install AdaNet\n",
        "!git clone https://github.com/tensorflow/adanet \\\n",
        "  && cd adanet \\\n",
        "  && bazel build //adanet/pip_package:build_pip_package \\\n",
        "  && bazel-bin/adanet/pip_package/build_pip_package /tmp/adanet_pkg \\\n",
        "  && pip install /tmp/adanet_pkg/*.whl \\\n",
        "  && cd ~ \\\n",
        "  && python -c \"import adanet\"\n",
        "\n",
        "# from adanet.examples import simple_dnn is not working.\n",
        "%run /content/adanet/adanet/examples/simple_dnn.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-30 23:10:37--  https://github.com/bazelbuild/bazel/releases/download/0.19.0/bazel-0.19.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/29a1a380-db91-11e8-989d-4be7267c69ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181030%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181030T231037Z&X-Amz-Expires=300&X-Amz-Signature=0ce072b319848ca4eb6e31428d1c0c12749ad1951a6968d4d3ff0cc01199860f&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.19.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-10-30 23:10:37--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/29a1a380-db91-11e8-989d-4be7267c69ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181030%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181030T231037Z&X-Amz-Expires=300&X-Amz-Signature=0ce072b319848ca4eb6e31428d1c0c12749ad1951a6968d4d3ff0cc01199860f&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.19.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.128.251\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.128.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166413740 (159M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.19.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-0.19.0-instal 100%[===================>] 158.70M  34.4MB/s    in 5.2s    \n",
            "\n",
            "2018-10-30 23:10:43 (30.8 MB/s) - ‘bazel-0.19.0-installer-linux-x86_64.sh’ saved [166413740/166413740]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.19.0 (2018-10-29)\n",
            "\n",
            "Baseline: ac880418885061d1039ad6b3d8c28949782e02d6\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + 9bc3b20053a8b99bf2c4a31323a7f96fabb9f1ec:\n",
            "     Fix the \"nojava\" platform and enable full presubmit checks for\n",
            "     the various JDK platforms now that we have enough GCE resources.\n",
            "   + 54c2572a8cabaf2b29e58abe9f04327314caa6a0:\n",
            "     Add openjdk_linux_archive java_toolchain for nojava platform.\n",
            "   + 20bfdc67dc1fc32ffebbda7088ba49ee17e3e182:\n",
            "     Automated rollback of commit\n",
            "     19a401c38e30ebc0879925a5caedcbe43de0028f.\n",
            "   + 914b4ce14624171a97ff8b41f9202058f10d15b2:\n",
            "     Windows: Fix Precondition check for addDynamicInputLinkOptions\n",
            "   + 83d406b7da32d1b1f6dd02eae2fe98582a4556fd:\n",
            "     Windows, test-setup.sh: Setting RUNFILES_MANIFEST_FILE only when\n",
            "     it exists.\n",
            "   + e025726006236520f7e91e196b9e7f139e0af5f4:\n",
            "     Update turbine\n",
            "   + 5f312dd1678878fb7563eae0cd184f2270346352:\n",
            "     Fix event id for action_completed BEP events\n",
            "\n",
            "The Bazel team is happy to announce a new version of Bazel, [Bazel 0.19](https://github.com/bazelbuild/bazel/releases/tag/0.19.0).\n",
            "\n",
            "This document lists the major changes since Bazel 0.18.\n",
            "\n",
            "General changes\n",
            "---------------\n",
            "\n",
            "* The `--incompatible_expand_directories` flag will automatically expand directories in command lines. Design doc: https://docs.google.com/document/d/11agWFiOUiz2htBLj6swPTob5z78TrCxm8DQE4uJLOwM\n",
            "\n",
            "* The `--loading_phase_threads` flag now defaults to `auto` (not 200, as was previously the case), which at the moment corresponds to the number of CPUs. This is appropriate for most users. However, if your sources reside on a network file system, increasing this value may yield better analysis-time performance when disk caches are cold.\n",
            "\n",
            "Android\n",
            "-------\n",
            "\n",
            "* Fixed missing debug symbols when building native code with `--compilation_mode=dbg` that target Android ARM architectures by adding the `-g` flag.\n",
            "\n",
            "C++\n",
            "---\n",
            "\n",
            "* Added `--incompatible_disable_legacy_flags_cc_toolchain_api` to deprecate legacy `cc_toolchain` Starlark API for legacy CROSSTOOL fields. Tracking issue is #6434. Migration docs are on the bazel website.\n",
            "\n",
            "* Runfiles in cc_test: the C++ runfiles library (`@bazel_tools//tools/cpp/runfiles`) can now create Runfiles objects for tests. See `//tools/cpp/runfiles/runfiles_src.h` (in the Bazel source tree) for documentation.\n",
            "\n",
            "* :cc_binary link action no longer hardcodes `-static-libgcc` for toolchains that support embedded runtimes (guarded by `--experimental_dont_emit_static_libgcc` temporarily).\n",
            "\n",
            "* The flag `--experimental_enable_cc_configuration_make_variables` is removed, use `--incompatible_disable_cc_configuration_make_variables` instead.\n",
            "\n",
            "Java\n",
            "----\n",
            "\n",
            "* If the `--javabase` flag is unset, Bazel locates a JDK using the `JAVA_HOME` environment variable and searching the PATH. If no JDK is found `--javabase` will be empty, and builds targeting Java will not be supported.  Previously Bazel would fall back to using the embedded JDK as a `--javabase`, but this is no longer default behaviour. A JDK should be explicitly installed instead to enable Java development.\n",
            "\n",
            "Code Coverage\n",
            "-------------\n",
            "\n",
            "* LcovMerger was renamed to CoverageOutputGenerator.\n",
            "\n",
            "* Faster coverage collection for gcc compiled C++ code can now be tested by enabling it with `--experimental_cc_coverage`.\n",
            "\n",
            "Other Changes\n",
            "-------------\n",
            "\n",
            "* Add `--apple_compiler` and `--apple_grte_top options`. These provide the equivalent of --compiler / --grte_top for the toolchain configured in --apple_crosstool_top.\n",
            "\n",
            "* There is now a `same_pkg_direct_rdeps` query function. See the query documentation for more details.\n",
            "\n",
            "* Propagating remote errors to the user even if `--verbose_failures=false` is set.\n",
            "\n",
            "* Add number of configured targets to analysis phase status output.\n",
            "\n",
            "* Bazel will now check stderr instead of stdout to decide if it is outputting to a terminal.  `--isatty` is deprecated, use `--is_stderr_atty` instead.\n",
            "\n",
            "Future Changes\n",
            "--------------\n",
            "\n",
            "* None of the C++ related incompatible flags mentioned in the 0.18 release were flipped, they will be flipped in the next release (0.20). We have created tracking issues for all the relevant incompatible flags:\n",
            "    * [`--incompatible_disable_late_bound_option_defaults`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-late-bound-option-defaults): #6384\n",
            "    * [`--incompatible_disable_depset_in_cc_user_flags`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-depsets-in-c-toolchain-api-in-user-flags): #6383\n",
            "    * [`--incompatible_disable_cc_toolchain_label_from_crosstool_proto`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disallow-using-crosstool-to-select-the-cc_toolchain-label): #6382\n",
            "    * [`--incompatible_disable_cc_configuration_make_variables`](https://github.com/bazelbuild/bazel/issues/6381): #6381\n",
            "    * [`--incompatible_disable_legacy_cpp_toolchain_skylark_api`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-legacy-c-configuration-api): #6380\n",
            "    * [`incompatible_disable_legacy_flags_cc_toolchain_api`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-legacy-c-toolchain-api): #6434\n",
            "\n",
            "* In the 0.20 release the flags [`--incompatible_remove_native_git_repository`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#remove-native-git-repository) and [`--incompatible_remove_native_http_archive`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#remove-native-http-archive) will be turned on.\n",
            "\n",
            "Thank you to our contributors!\n",
            "------------------------------\n",
            "\n",
            "This release contains contributions from many people at Google, as well as Andreas Herrmann, Andreas Hippler, Benjamin Peterson, David Ostrovsky, Ed Baunton, George Gensure, Igal Tabachnik, Jason Gavris, Loo Rong Jie, rmalik, and Yannic Bonenberger\n",
            "\n",
            "Thank you to everyone who contributed to this release!\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/f0c844c)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/root/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /root/.bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "Cloning into 'adanet'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 610 (delta 77), reused 92 (delta 45), pack-reused 470\u001b[K\n",
            "Receiving objects: 100% (610/610), 475.87 KiB | 1.92 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n",
            "Extracting Bazel installation...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "Starting local Bazel server and connecting to it...\n",
            "\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (1 packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (2 packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (3 packages loaded, 0\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (4 packages loaded, 1\\\n",
            "9 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (9 packages loaded, 3\\\n",
            "8 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (12 packages loaded, \\\n",
            "51 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "74 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "\u001b[32mINFO: \u001b[0mSHA256 (https://github.com/google/protobuf/archive/ab8edf1dbe2237b4717869eaab11a2998541ad8d.tar.gz) = 56541023a5dfa05de7dd5b7856bfd370047d6b93718eba068b43d1a4092b6cb6\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "90 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (14 packages loaded, \\\n",
            "101 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (15 packages loaded, \\\n",
            "105 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "126 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mINFO: \u001b[0mSHA256 (https://github.com/google/protobuf/archive/v3.6.0.zip) = e514c2e613dc47c062ea8df480efeec368ffbef98af0437ac00cdaadcb0d80d2\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "126 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (18 packages loaded, \\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //adanet/pip_package:build_pip_package (18 packages loaded, 609 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "\u001b[32m[4 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[4 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[5 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[5 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[5 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[5 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[6 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[7 / 11]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[8 / 12]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[8 / 12]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[9 / 13]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[9 / 13]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[9 / 13]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[9 / 13]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[10 / 14]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[10 / 14]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[10 / 14]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[11 / 15]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[12 / 16]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[12 / 16]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[13 / 17]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[13 / 17]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[14 / 18]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[14 / 18]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[15 / 19]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[16 / 20]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[16 / 20]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[16 / 20]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[17 / 21]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[17 / 21]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[17 / 21]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[18 / 22]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[18 / 22]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[19 / 23]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[19 / 23]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[21 / 25]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[22 / 26]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[22 / 26]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[22 / 26]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[22 / 26]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[23 / 27]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[24 / 28]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[24 / 28]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[25 / 29]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[25 / 29]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[26 / 30]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[26 / 30]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[26 / 30]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[27 / 31]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[28 / 32]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[29 / 33]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[29 / 33]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[30 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[30 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[30 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[30 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[31 / 35]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[32 / 36]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[32 / 36]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[32 / 36]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[33 / 37]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[34 / 38]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[34 / 38]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[34 / 38]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[35 / 39]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[35 / 39]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[35 / 39]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[37 / 41]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[37 / 41]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[38 / 42]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[38 / 42]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[40 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[40 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[40 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[40 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[41 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[41 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[41 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[41 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[41 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[42 / 46]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[42 / 46]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[43 / 47]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[43 / 47]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[45 / 49]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[45 / 49]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[46 / 53]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[48 / 55]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[50 / 57]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:js_embed; 0s processwrapper-sandbox\n",
            "\u001b[32m[51 / 58]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:js_embed; 0s processwrapper-sandbox\n",
            "\u001b[32m[52 / 59]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[52 / 59]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[54 / 61]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[54 / 61]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[54 / 61]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[55 / 62]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[55 / 62]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[56 / 63]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[56 / 63]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[57 / 64]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[58 / 65]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[59 / 66]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[60 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[60 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[60 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[60 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 9s processwrapper-sandbox\n",
            "\u001b[32m[61 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 10s processwrapper-sandbox\n",
            "\u001b[32m[62 / 69]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 11s processwrapper-sandbox\n",
            "\u001b[32m[62 / 69]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 12s processwrapper-sandbox\n",
            "\u001b[32m[63 / 70]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[63 / 70]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[63 / 70]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[64 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[64 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[64 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[65 / 72]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[65 / 72]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[65 / 72]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[66 / 73]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[66 / 73]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[66 / 73]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[67 / 74]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[67 / 74]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[67 / 74]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s processwrapper-sandbox\n",
            "\u001b[32m[68 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s processwrapper-sandbox\n",
            "\u001b[32m[68 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[68 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 9s processwrapper-sandbox\n",
            "\u001b[32m[68 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 10s processwrapper-sandbox\n",
            "\u001b[32m[68 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 11s processwrapper-sandbox\n",
            "\u001b[32m[69 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 12s processwrapper-sandbox\n",
            "\u001b[32m[69 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 13s processwrapper-sandbox\n",
            "\u001b[32m[69 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 14s processwrapper-sandbox\n",
            "\u001b[32m[69 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 15s processwrapper-sandbox\n",
            "\u001b[32m[70 / 77]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 15s processwrapper-sandbox\n",
            "\u001b[32m[70 / 77]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 16s processwrapper-sandbox\n",
            "\u001b[32m[70 / 77]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 17s processwrapper-sandbox\n",
            "\u001b[32m[71 / 78]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[71 / 78]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[73 / 80]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[74 / 81]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[74 / 81]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[75 / 82]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[76 / 83]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[76 / 83]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[76 / 83]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[77 / 84]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[77 / 84]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[78 / 85]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[78 / 85]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[79 / 86]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[80 / 87]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[81 / 88]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[81 / 88]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[81 / 88]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[81 / 88]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 4s processwrapper-sandbox\n",
            "\u001b[32m[82 / 89]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[83 / 90]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[83 / 90]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[84 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[84 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[84 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[86 / 93]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[86 / 93]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[87 / 94]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[87 / 94]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[87 / 94]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[87 / 94]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[88 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[88 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[89 / 96]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[89 / 96]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[90 / 97]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[91 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[91 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[91 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[92 / 99]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[92 / 99]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[93 / 100]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[93 / 100]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[94 / 101]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[94 / 101]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[94 / 101]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[95 / 102]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[95 / 102]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[96 / 103]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[98 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[98 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[99 / 106]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[99 / 106]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[100 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[100 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[100 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[100 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[102 / 109]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[103 / 110]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[104 / 111]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[105 / 112]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[105 / 112]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[107 / 114]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[107 / 114]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[108 / 115]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[108 / 115]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[109 / 116]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[110 / 117]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[110 / 117]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[111 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[111 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[112 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[112 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[112 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[113 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[113 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[116 / 123]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[116 / 123]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[116 / 123]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[117 / 124]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[118 / 125]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[119 / 126]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[119 / 126]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[121 / 128]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[122 / 129]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[122 / 129]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[122 / 129]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[123 / 130]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[123 / 130]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[123 / 130]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[124 / 131]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[124 / 131]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[124 / 131]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[125 / 132]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[125 / 132]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[125 / 132]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[126 / 133]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[127 / 134]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[127 / 134]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[128 / 135]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[129 / 136]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[129 / 136]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[130 / 136]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[133 / 137]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[134 / 138]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[134 / 138]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[135 / 139]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[135 / 139]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[136 / 140]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[136 / 140]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[137 / 141]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[138 / 142]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[139 / 143]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[139 / 143]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[139 / 143]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[141 / 145]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[142 / 146]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[143 / 147]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[143 / 147]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[144 / 148]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[144 / 148]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[145 / 149]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[145 / 149]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[146 / 150]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[147 / 151]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[147 / 151]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[148 / 152]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[148 / 152]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[149 / 153]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[149 / 153]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[150 / 154]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[150 / 154]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[151 / 155]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[151 / 155]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[152 / 156]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[152 / 156]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[152 / 156]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[153 / 157]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[154 / 158]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[155 / 159]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[156 / 160]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[156 / 160]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[157 / 161]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[158 / 162]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[158 / 162]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[159 / 163]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[160 / 164]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[160 / 164]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[161 / 165]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[161 / 165]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[161 / 165]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[162 / 166]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[162 / 166]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[162 / 166]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[163 / 167]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 8s processwrapper-sandbox\n",
            "\u001b[32m[163 / 167]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 8s processwrapper-sandbox\n",
            "\u001b[32m[163 / 167]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 9s processwrapper-sandbox\n",
            "\u001b[32m[164 / 168]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[166 / 170]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[167 / 171]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[168 / 172]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[168 / 172]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[168 / 172]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[168 / 172]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[170 / 174]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[170 / 174]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[171 / 175]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[171 / 175]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[172 / 176]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32mINFO: \u001b[0mFrom ProtoCompile external/com_google_protobuf/python/google/protobuf/any_pb2.py:\n",
            "external/com_google_protobuf/python: warning: directory does not exist.\n",
            "Target //adanet/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/adanet/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 265.244s, Critical Path: 17.88s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\n",
            "\u001b[32mINFO: \u001b[0m170 processes: 170 processwrapper-sandbox.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 180 total actions\n",
            "\u001b[0mTue Oct 30 23:15:20 UTC 2018 : === Using tmpdir: /tmp/E5TvYcfPQ5qjCKIVguAOgQN_adanet_pip_pkg\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (0 packages loaded, 0\\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //adanet/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "Target //adanet/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/adanet/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 0.306s, Critical Path: 0.00s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
            "\u001b[0m/tmp/E5TvYcfPQ5qjCKIVguAOgQN_adanet_pip_pkg /content/adanet\n",
            "Tue Oct 30 23:15:21 UTC 2018 : === Building universal python wheel in /tmp/E5TvYcfPQ5qjCKIVguAOgQN_adanet_pip_pkg\n",
            "/content/adanet\n",
            "Tue Oct 30 23:15:21 UTC 2018 : === Output wheel files are in: /tmp/adanet_pkg\n",
            "Processing /tmp/adanet_pkg/adanet-0.1.0.dev0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.4.0->adanet==0.1.0.dev0) (40.5.0)\n",
            "Installing collected packages: adanet\n",
            "Successfully installed adanet-0.1.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "q4WF3l23pumU"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The AdaNet Authors."
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "Kic2quJWppmx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aL7SpaKdirqG"
      },
      "cell_type": "markdown",
      "source": [
        "# Customizing AdaNet\n",
        "\n",
        "Often times, as a researcher or machine learning practitioner, you will have\n",
        "some prior knowledge about a dataset. Ideally you should be able to encode that\n",
        "knowledge into your machine learning algorithm. With `adanet`, you can do so by\n",
        "defining the *neural architecture search space* that the AdaNet algorithm should\n",
        "explore.\n",
        "\n",
        "In this tutorial, we will explore the flexibility of the `adanet` framework, and\n",
        "create a custom search space for an image-classificatio dataset using high-level\n",
        "TensorFlow libraries like `tf.layers`.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x_3b6xx2s6B9",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "\n",
        "import adanet\n",
        "#from adanet.examples import simple_dnn\n",
        "import tensorflow as tf\n",
        "\n",
        "# The random seed to use.\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7gE5Mm9j2oYw"
      },
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST dataset\n",
        "\n",
        "In this example, we will use the Fashion MNIST dataset\n",
        "[[Xiao et al., 2017](https://arxiv.org/abs/1708.07747)] for classifying fashion\n",
        "apparel images into one of ten categories:\n",
        "\n",
        "1.  T-shirt/top\n",
        "2.  Trouser\n",
        "3.  Pullover\n",
        "4.  Dress\n",
        "5.  Coat\n",
        "6.  Sandal\n",
        "7.  Shirt\n",
        "8.  Sneaker\n",
        "9.  Bag\n",
        "10. Ankle boot\n",
        "\n",
        "![Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5_hRtdchqRZb"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the data\n",
        "\n",
        "Conveniently, the data is available via Keras:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uYklOnPJ4h7g",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7866f0ac-69a4-415d-bb5f-e79ec80eacf9"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = (\n",
        "    tf.keras.datasets.mnist.load_data())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tECo5dFd4QCa"
      },
      "cell_type": "markdown",
      "source": [
        "## Supply the data in TensorFlow\n",
        "\n",
        "Our first task is to supply the data in TensorFlow. Using the\n",
        "tf.estimator.Estimator covention, we will define a function that returns an\n",
        "`input_fn` which returns feature and label `Tensors`.\n",
        "\n",
        "We will also use the `tf.data.Dataset` API to feed the data into our models."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gxTAoIXwsTH7",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "FEATURES_KEY = \"images\"\n",
        "\n",
        "\n",
        "def generator(images, labels):\n",
        "  \"\"\"Returns a generator that returns image-label pairs.\"\"\"\n",
        "\n",
        "  def _gen():\n",
        "    for image, label in zip(images, labels):\n",
        "      yield image, label\n",
        "\n",
        "  return _gen\n",
        "\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "  \"\"\"Preprocesses an image for an `Estimator`.\"\"\"\n",
        "  # First let's scale the pixel values to be between 0 and 1.\n",
        "  image = image / 255.\n",
        "  # Next we reshape the image so that we can apply a 2D convolution to it.\n",
        "  image = tf.reshape(image, [28, 28, 1])\n",
        "  # Finally the features need to be supplied as a dictionary.\n",
        "  features = {FEATURES_KEY: image}\n",
        "  return features, label\n",
        "\n",
        "\n",
        "def input_fn(partition, training, batch_size):\n",
        "  \"\"\"Generate an input_fn for the Estimator.\"\"\"\n",
        "\n",
        "  def _input_fn():\n",
        "    if partition == \"train\":\n",
        "      dataset = tf.data.Dataset.from_generator(\n",
        "          generator(x_train, y_train), (tf.float32, tf.int32), ((28, 28), ()))\n",
        "    else:\n",
        "      dataset = tf.data.Dataset.from_generator(\n",
        "          generator(x_test, y_test), (tf.float32, tf.int32), ((28, 28), ()))\n",
        "\n",
        "    # We call repeat after shuffling, rather than before, to prevent separate\n",
        "    # epochs from blending together.\n",
        "    if training:\n",
        "      dataset = dataset.shuffle(10 * batch_size, seed=RANDOM_SEED).repeat()\n",
        "\n",
        "    dataset = dataset.map(preprocess_image).batch(batch_size)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    features, labels = iterator.get_next()\n",
        "    return features, labels\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vm9yudEv5lQZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Establish baselines\n",
        "\n",
        "The next task should be to get somes baselines to see how our model performs on\n",
        "this dataset.\n",
        "\n",
        "Let's define some information to share with all our `tf.estimator.Estimators`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xNwSUWh-9_Ib",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# The number of classes.\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# We will average the losses in each mini-batch when computing gradients.\n",
        "loss_reduction = tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        "\n",
        "# A `Head` instance defines the loss function and metrics for `Estimators`.\n",
        "head = tf.contrib.estimator.multi_class_head(\n",
        "    NUM_CLASSES, loss_reduction=loss_reduction)\n",
        "\n",
        "# Some `Estimators` use feature columns for understanding their input features.\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(FEATURES_KEY, shape=[28, 28, 1])\n",
        "]\n",
        "\n",
        "# Estimator configuration.\n",
        "config = tf.estimator.RunConfig(\n",
        "    save_checkpoints_steps=50000,\n",
        "    save_summary_steps=50000,\n",
        "    tf_random_seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QY0cv-ot-Gxs"
      },
      "cell_type": "markdown",
      "source": [
        "Let's start simple, and train a linear model:"
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "s8wJKsi06blX",
        "outputId": "e34ba1d8-3391-49be-a657-25b97420ebc1",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 2264
        }
      },
      "cell_type": "code",
      "source": [
        "#@test {\"skip\": true}\n",
        "#@title Parameters\n",
        "LEARNING_RATE = 0.001  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "\n",
        "estimator = tf.estimator.LinearClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    n_classes=NUM_CLASSES,\n",
        "    optimizer=tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE),\n",
        "    loss_reduction=loss_reduction,\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1Rx__N\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd4ba882cd0>, '_model_dir': '/tmp/tmp1Rx__N', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1Rx__N/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3025851, step = 0\n",
            "INFO:tensorflow:global_step/sec: 59.5804\n",
            "INFO:tensorflow:loss = 1.3225186, step = 100 (1.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.4302\n",
            "INFO:tensorflow:loss = 0.6913334, step = 200 (1.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1029\n",
            "INFO:tensorflow:loss = 0.37077364, step = 300 (1.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.5367\n",
            "INFO:tensorflow:loss = 0.56232077, step = 400 (1.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.6058\n",
            "INFO:tensorflow:loss = 0.31495035, step = 500 (1.798 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0746\n",
            "INFO:tensorflow:loss = 0.21376616, step = 600 (1.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7115\n",
            "INFO:tensorflow:loss = 0.2782115, step = 700 (1.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.532\n",
            "INFO:tensorflow:loss = 0.33467185, step = 800 (1.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.9948\n",
            "INFO:tensorflow:loss = 0.2974522, step = 900 (1.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.2986\n",
            "INFO:tensorflow:loss = 0.3031894, step = 1000 (1.776 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7485\n",
            "INFO:tensorflow:loss = 0.32642654, step = 1100 (1.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.9088\n",
            "INFO:tensorflow:loss = 0.34919757, step = 1200 (1.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.832\n",
            "INFO:tensorflow:loss = 0.2163453, step = 1300 (1.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0667\n",
            "INFO:tensorflow:loss = 0.3045628, step = 1400 (1.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7315\n",
            "INFO:tensorflow:loss = 0.23112144, step = 1500 (1.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8591\n",
            "INFO:tensorflow:loss = 0.42135495, step = 1600 (1.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.6697\n",
            "INFO:tensorflow:loss = 0.34508914, step = 1700 (1.797 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8395\n",
            "INFO:tensorflow:loss = 0.24383736, step = 1800 (1.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.3226\n",
            "INFO:tensorflow:loss = 0.28901023, step = 1900 (1.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.912\n",
            "INFO:tensorflow:loss = 0.23797706, step = 2000 (1.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.3892\n",
            "INFO:tensorflow:loss = 0.241463, step = 2100 (1.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.3728\n",
            "INFO:tensorflow:loss = 0.33191007, step = 2200 (1.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1457\n",
            "INFO:tensorflow:loss = 0.25531214, step = 2300 (1.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.805\n",
            "INFO:tensorflow:loss = 0.2085185, step = 2400 (1.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8015\n",
            "INFO:tensorflow:loss = 0.21551134, step = 2500 (1.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1292\n",
            "INFO:tensorflow:loss = 0.23731002, step = 2600 (1.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0171\n",
            "INFO:tensorflow:loss = 0.30849677, step = 2700 (1.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.789\n",
            "INFO:tensorflow:loss = 0.17739734, step = 2800 (1.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.4104\n",
            "INFO:tensorflow:loss = 0.40056008, step = 2900 (1.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.843\n",
            "INFO:tensorflow:loss = 0.36385673, step = 3000 (1.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.462\n",
            "INFO:tensorflow:loss = 0.19954777, step = 3100 (1.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1565\n",
            "INFO:tensorflow:loss = 0.43056262, step = 3200 (1.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7848\n",
            "INFO:tensorflow:loss = 0.5477644, step = 3300 (1.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0726\n",
            "INFO:tensorflow:loss = 0.36613417, step = 3400 (1.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.6726\n",
            "INFO:tensorflow:loss = 0.18359983, step = 3500 (1.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.363\n",
            "INFO:tensorflow:loss = 0.20303303, step = 3600 (1.806 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7517\n",
            "INFO:tensorflow:loss = 0.24621977, step = 3700 (1.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0553\n",
            "INFO:tensorflow:loss = 0.4621722, step = 3800 (1.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8692\n",
            "INFO:tensorflow:loss = 0.23732667, step = 3900 (1.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.128\n",
            "INFO:tensorflow:loss = 0.2790661, step = 4000 (1.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.9059\n",
            "INFO:tensorflow:loss = 0.2575125, step = 4100 (1.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1615\n",
            "INFO:tensorflow:loss = 0.5643626, step = 4200 (1.780 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0379\n",
            "INFO:tensorflow:loss = 0.46703285, step = 4300 (1.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8596\n",
            "INFO:tensorflow:loss = 0.39612246, step = 4400 (1.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.1209\n",
            "INFO:tensorflow:loss = 0.4562729, step = 4500 (1.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.802\n",
            "INFO:tensorflow:loss = 0.34617063, step = 4600 (1.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.8631\n",
            "INFO:tensorflow:loss = 0.42493638, step = 4700 (1.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7528\n",
            "INFO:tensorflow:loss = 0.26857808, step = 4800 (1.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.0781\n",
            "INFO:tensorflow:loss = 0.22215933, step = 4900 (1.783 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp1Rx__N/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-23:24:31\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1Rx__N/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-23:24:34\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9258, average_loss = 0.27285188, global_step = 5000, loss = 0.27215475\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp1Rx__N/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.13550891.\n",
            "Accuracy: 0.9258\n",
            "Loss: 0.27285188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a-1hE03c7_Yj"
      },
      "cell_type": "markdown",
      "source": [
        "The linear model with default parameters achieves about **84.13% accuracy**.\n",
        "\n",
        "Let's see if we can do better with the `simple_dnn` AdaNet:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9fAoRYd19eUs",
        "outputId": "ba1d7a4c-146e-45f5-ddcb-63144132dd5f",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 3352
        }
      },
      "cell_type": "code",
      "source": [
        "#@test {\"skip\": true}\n",
        "#@title Parameters\n",
        "LEARNING_RATE = 0.003  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "ADANET_ITERATIONS = 2  #@param {type:\"integer\"}\n",
        "\n",
        "estimator = adanet.Estimator(\n",
        "    head=head,\n",
        "    subnetwork_generator=Generator(\n",
        "        feature_columns=feature_columns,\n",
        "        optimizer=tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE),\n",
        "        seed=RANDOM_SEED),\n",
        "    max_iteration_steps=TRAIN_STEPS // ADANET_ITERATIONS,\n",
        "    evaluator=adanet.Evaluator(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpEwW52D\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd4b3855910>, '_model_dir': '/tmp/tmpEwW52D', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 0\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpEwW52D/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3048944, step = 0\n",
            "INFO:tensorflow:global_step/sec: 40.0789\n",
            "INFO:tensorflow:loss = 0.67115676, step = 100 (2.496 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.7185\n",
            "INFO:tensorflow:loss = 0.31763986, step = 200 (2.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.767\n",
            "INFO:tensorflow:loss = 0.16151033, step = 300 (2.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.9123\n",
            "INFO:tensorflow:loss = 0.3246523, step = 400 (2.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0306\n",
            "INFO:tensorflow:loss = 0.14924045, step = 500 (2.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.8547\n",
            "INFO:tensorflow:loss = 0.07197815, step = 600 (2.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.8527\n",
            "INFO:tensorflow:loss = 0.0883112, step = 700 (2.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.5676\n",
            "INFO:tensorflow:loss = 0.10245603, step = 800 (2.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.8737\n",
            "INFO:tensorflow:loss = 0.082594685, step = 900 (2.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7147\n",
            "INFO:tensorflow:loss = 0.2905597, step = 1000 (2.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.247\n",
            "INFO:tensorflow:loss = 0.11370945, step = 1100 (2.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5234\n",
            "INFO:tensorflow:loss = 0.0889602, step = 1200 (2.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.641\n",
            "INFO:tensorflow:loss = 0.05261237, step = 1300 (2.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9006\n",
            "INFO:tensorflow:loss = 0.16187902, step = 1400 (2.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.3632\n",
            "INFO:tensorflow:loss = 0.08165164, step = 1500 (2.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7031\n",
            "INFO:tensorflow:loss = 0.24000281, step = 1600 (2.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.7069\n",
            "INFO:tensorflow:loss = 0.113270566, step = 1700 (2.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0543\n",
            "INFO:tensorflow:loss = 0.12082761, step = 1800 (2.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.9609\n",
            "INFO:tensorflow:loss = 0.105430305, step = 1900 (2.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0173\n",
            "INFO:tensorflow:loss = 0.029110907, step = 2000 (2.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.9576\n",
            "INFO:tensorflow:loss = 0.11788218, step = 2100 (2.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0444\n",
            "INFO:tensorflow:loss = 0.14209235, step = 2200 (2.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.1886\n",
            "INFO:tensorflow:loss = 0.17022021, step = 2300 (2.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0774\n",
            "INFO:tensorflow:loss = 0.08514095, step = 2400 (2.124 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmpEwW52D/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-23:25:35\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpEwW52D/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'linear' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.9238, accuracy/adanet/subnetwork = 0.9238, accuracy/adanet/uniform_average_ensemble = 0.9238, architecture/adanet/ensembles = \n",
            "T\n",
            "6adanet/iteration_0/ensemble_linear/architecture/adanetB\u0010\b\u0007\u0012\u0000B\n",
            "| linear |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.2854871, average_loss/adanet/subnetwork = 0.2854871, average_loss/adanet/uniform_average_ensemble = 0.2854871, loss/adanet/adanet_weighted_ensemble = 0.2844932, loss/adanet/subnetwork = 0.2844932, loss/adanet/uniform_average_ensemble = 0.2844932\n",
            "INFO:tensorflow:Saving candidate '1_layer_dnn' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.957, accuracy/adanet/subnetwork = 0.957, accuracy/adanet/uniform_average_ensemble = 0.957, architecture/adanet/ensembles = \n",
            "^\n",
            ";adanet/iteration_0/ensemble_1_layer_dnn/architecture/adanetB\u0015\b\u0007\u0012\u0000B\u000f| 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.14346275, average_loss/adanet/subnetwork = 0.14346275, average_loss/adanet/uniform_average_ensemble = 0.14346275, loss/adanet/adanet_weighted_ensemble = 0.14280921, loss/adanet/subnetwork = 0.14280921, loss/adanet/uniform_average_ensemble = 0.14280921\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-23:25:41\n",
            "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.957, accuracy/adanet/adanet_weighted_ensemble = 0.957, accuracy/adanet/subnetwork = 0.957, accuracy/adanet/uniform_average_ensemble = 0.957, average_loss = 0.14346275, average_loss/adanet/adanet_weighted_ensemble = 0.14346275, average_loss/adanet/subnetwork = 0.14346275, average_loss/adanet/uniform_average_ensemble = 0.14346275, global_step = 2500, loss = 0.14280921, loss/adanet/adanet_weighted_ensemble = 0.14280921, loss/adanet/subnetwork = 0.14280921, loss/adanet/uniform_average_ensemble = 0.14280921\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmpEwW52D/model.ckpt-2500\n",
            "INFO:tensorflow:Loss for final step: 0.09594996.\n",
            "INFO:tensorflow:Starting ensemble evaluation for iteration 0\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpEwW52D/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Encountered end of input after 939 evaluations\n",
            "INFO:tensorflow:Computed ensemble metrics: adanet_loss/linear = 0.273420, adanet_loss/1_layer_dnn = 0.117683\n",
            "INFO:tensorflow:Finished ensemble evaluation for iteration 0\n",
            "INFO:tensorflow:'1_layer_dnn' at index 1 is moving onto the next iteration\n",
            "INFO:tensorflow:Freezing best ensemble to /tmp/tmpEwW52D/frozen/ensemble-0.meta\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpEwW52D/model.ckpt-2500\n",
            "INFO:tensorflow:Froze 5 variables.\n",
            "INFO:tensorflow:Converted 5 variables to const ops.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpEwW52D/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Overwriting checkpoint with new graph for iteration 1 to /tmp/tmpEwW52D/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Finished training Adanet iteration 0\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpEwW52D/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpEwW52D/increment.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmpEwW52D/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.10201882, step = 2500\n",
            "INFO:tensorflow:global_step/sec: 35.7212\n",
            "INFO:tensorflow:loss = 0.047877565, step = 2600 (2.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6071\n",
            "INFO:tensorflow:loss = 0.06869449, step = 2700 (2.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5983\n",
            "INFO:tensorflow:loss = 0.11082457, step = 2800 (2.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.465\n",
            "INFO:tensorflow:loss = 0.20001385, step = 2900 (2.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3336\n",
            "INFO:tensorflow:loss = 0.06507362, step = 3000 (2.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.2706\n",
            "INFO:tensorflow:loss = 0.010006099, step = 3100 (2.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7954\n",
            "INFO:tensorflow:loss = 0.032594524, step = 3200 (2.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7954\n",
            "INFO:tensorflow:loss = 0.038037777, step = 3300 (2.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6134\n",
            "INFO:tensorflow:loss = 0.05235568, step = 3400 (2.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.4706\n",
            "INFO:tensorflow:loss = 0.17537852, step = 3500 (2.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3677\n",
            "INFO:tensorflow:loss = 0.07411386, step = 3600 (2.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.4072\n",
            "INFO:tensorflow:loss = 0.059415992, step = 3700 (2.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6161\n",
            "INFO:tensorflow:loss = 0.05223314, step = 3800 (2.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.941\n",
            "INFO:tensorflow:loss = 0.09573622, step = 3900 (2.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3994\n",
            "INFO:tensorflow:loss = 0.08806134, step = 4000 (2.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5942\n",
            "INFO:tensorflow:loss = 0.21460012, step = 4100 (2.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5952\n",
            "INFO:tensorflow:loss = 0.07044667, step = 4200 (2.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.1839\n",
            "INFO:tensorflow:loss = 0.0902993, step = 4300 (2.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.4443\n",
            "INFO:tensorflow:loss = 0.06242504, step = 4400 (2.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3437\n",
            "INFO:tensorflow:loss = 0.01622987, step = 4500 (2.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3823\n",
            "INFO:tensorflow:loss = 0.103249356, step = 4600 (2.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.2538\n",
            "INFO:tensorflow:loss = 0.073778406, step = 4700 (2.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3275\n",
            "INFO:tensorflow:loss = 0.15089598, step = 4800 (2.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.423\n",
            "INFO:tensorflow:loss = 0.08775906, step = 4900 (2.303 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpEwW52D/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpEwW52D/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-23:27:08\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpEwW52D/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'previous_ensemble' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.957, accuracy/adanet/subnetwork = 0.957, accuracy/adanet/uniform_average_ensemble = 0.957, architecture/adanet/ensembles = \n",
            "O\n",
            ",adanet/previous_ensemble/architecture/adanetB\u0015\b\u0007\u0012\u0000B\u000f| 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.14346275, average_loss/adanet/subnetwork = 0.14346275, average_loss/adanet/uniform_average_ensemble = 0.14346275, loss/adanet/adanet_weighted_ensemble = 0.14280921, loss/adanet/subnetwork = 0.14280921, loss/adanet/uniform_average_ensemble = 0.14280921\n",
            "INFO:tensorflow:Saving candidate '1_layer_dnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.9638, accuracy/adanet/subnetwork = 0.9607, accuracy/adanet/uniform_average_ensemble = 0.9638, architecture/adanet/ensembles = \n",
            "l\n",
            ";adanet/iteration_1/ensemble_1_layer_dnn/architecture/adanetB#\b\u0007\u0012\u0000B\u001d| 1_layer_dnn | 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.12294396, average_loss/adanet/subnetwork = 0.14231513, average_loss/adanet/uniform_average_ensemble = 0.12294396, loss/adanet/adanet_weighted_ensemble = 0.12236651, loss/adanet/subnetwork = 0.14164457, loss/adanet/uniform_average_ensemble = 0.12236651\n",
            "INFO:tensorflow:Saving candidate '2_layer_dnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.9642, accuracy/adanet/subnetwork = 0.9609, accuracy/adanet/uniform_average_ensemble = 0.9642, architecture/adanet/ensembles = \n",
            "l\n",
            ";adanet/iteration_1/ensemble_2_layer_dnn/architecture/adanetB#\b\u0007\u0012\u0000B\u001d| 1_layer_dnn | 2_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.118783176, average_loss/adanet/subnetwork = 0.13345906, average_loss/adanet/uniform_average_ensemble = 0.118783176, loss/adanet/adanet_weighted_ensemble = 0.11823943, loss/adanet/subnetwork = 0.13285719, loss/adanet/uniform_average_ensemble = 0.11823943\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-23:27:15\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.957, accuracy/adanet/adanet_weighted_ensemble = 0.957, accuracy/adanet/subnetwork = 0.957, accuracy/adanet/uniform_average_ensemble = 0.957, average_loss = 0.14346275, average_loss/adanet/adanet_weighted_ensemble = 0.14346275, average_loss/adanet/subnetwork = 0.14346275, average_loss/adanet/uniform_average_ensemble = 0.14346275, global_step = 5000, loss = 0.14280921, loss/adanet/adanet_weighted_ensemble = 0.14280921, loss/adanet/subnetwork = 0.14280921, loss/adanet/uniform_average_ensemble = 0.14280921\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpEwW52D/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.029671988.\n",
            "Accuracy: 0.957\n",
            "Loss: 0.14346275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ysWsJ3zXDwNx"
      },
      "cell_type": "markdown",
      "source": [
        "The `simple_dnn` AdaNet model with default parameters achieves about **85.66%\n",
        "accuracy**.\n",
        "\n",
        "This improvement can be attributed to `simple_dnn` searching over\n",
        "fully-connected neural networks which have more expressive power than the linear\n",
        "model due to their non-linear activations.\n",
        "\n",
        "Fully-connected layers are permutation invariant to their inputs, meaning that\n",
        "if we consistently swapped two pixels before training, the final model would\n",
        "perform identically. However, there is spatial and locality information in\n",
        "images that we should try to capture. Applying a few convolutions to our inputs\n",
        "will allow us to do so, and that will require defining a custom\n",
        "`adanet.subnetwork.Builder` and `adanet.subnetwork.Generator`."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "D3IE6-9vFVlg"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a convolutional AdaNet model\n",
        "\n",
        "Creating a new search space for AdaNet to explore is straightforward. There are\n",
        "two abstract classes you need to extend:\n",
        "\n",
        "1.  `adanet.subnetwork.Builder`\n",
        "2.  `adanet.subnetwork.Generator`\n",
        "\n",
        "Similar to the tf.estimator.Estimator `model_fn`, `adanet.subnetwork.Builder`\n",
        "allows you to define your own TensorFlow graph for creating a neural network,\n",
        "and specify the training operations.\n",
        "\n",
        "Below we define one that applies a 2D convolution, max-pooling, and then a\n",
        "fully-connected layer to the images:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IsYJ97tRwBkt",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SimpleCNNBuilder(adanet.subnetwork.Builder):\n",
        "  \"\"\"Builds a CNN subnetwork for AdaNet.\"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate, max_iteration_steps, seed):\n",
        "    \"\"\"Initializes a `SimpleCNNBuilder`.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: The float learning rate to use.\n",
        "      max_iteration_steps: The number of steps per iteration.\n",
        "      seed: The random seed.\n",
        "\n",
        "    Returns:\n",
        "      An instance of `SimpleCNNBuilder`.\n",
        "    \"\"\"\n",
        "    self._learning_rate = learning_rate\n",
        "    self._max_iteration_steps = max_iteration_steps\n",
        "    self._seed = seed\n",
        "\n",
        "  def build_subnetwork(self,\n",
        "                       features,\n",
        "                       logits_dimension,\n",
        "                       training,\n",
        "                       iteration_step,\n",
        "                       summary,\n",
        "                       previous_ensemble=None):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    images = features.values()[0]\n",
        "    kernel_initializer = tf.keras.initializers.he_normal(seed=self._seed)\n",
        "    x = tf.layers.conv2d(\n",
        "        images,\n",
        "        filters=16,\n",
        "        kernel_size=3,\n",
        "        padding=\"same\",\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer)\n",
        "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2)\n",
        "    x = tf.layers.flatten(x)\n",
        "    x = tf.layers.dense(\n",
        "        x, units=64, activation=\"relu\", kernel_initializer=kernel_initializer)\n",
        "\n",
        "    # The `Head` passed to adanet.Estimator will apply the softmax activation.\n",
        "    logits = tf.layers.dense(\n",
        "        x, units=10, activation=None, kernel_initializer=kernel_initializer)\n",
        "\n",
        "    # Use a constant complexity measure, since all subnetworks have the same\n",
        "    # architecture and hyperparameters.\n",
        "    complexity = tf.constant(1)\n",
        "\n",
        "    return adanet.Subnetwork(\n",
        "        last_layer=x,\n",
        "        logits=logits,\n",
        "        complexity=complexity,\n",
        "        persisted_tensors={})\n",
        "\n",
        "  def build_subnetwork_train_op(self, \n",
        "                                subnetwork, \n",
        "                                loss, \n",
        "                                var_list, \n",
        "                                labels, \n",
        "                                iteration_step,\n",
        "                                summary, \n",
        "                                previous_ensemble=None):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "\n",
        "    # Momentum optimizer with cosine learning rate decay works well with CNNs.\n",
        "    learning_rate = tf.train.cosine_decay(\n",
        "        learning_rate=self._learning_rate,\n",
        "        global_step=iteration_step,\n",
        "        decay_steps=self._max_iteration_steps)\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate, .9)\n",
        "    # NOTE: The `adanet.Estimator` increments the global step.\n",
        "    return optimizer.minimize(loss=loss, var_list=var_list)\n",
        "\n",
        "  def build_mixture_weights_train_op(self, loss, var_list, logits, labels,\n",
        "                                     iteration_step, summary):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    return tf.no_op(\"mixture_weights_train_op\")\n",
        "\n",
        "  @property\n",
        "  def name(self):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    return \"simple_cnn\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OFamPrZHJ5ii"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we extend a `adanet.subnetwork.Generator`, which defines the search\n",
        "space of candidate `SimpleCNNBuilders` to consider including the final network.\n",
        "It can create one or more at each iteration with different parameters, and the\n",
        "AdaNet algorithm will select the candidate that best improves the overall neural\n",
        "network's `adanet_loss` on the training set.\n",
        "\n",
        "The one below is very simple: it always creates the same architecture, but gives\n",
        "it a different random seed at each iteration:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BAnb_XGwhRy",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SimpleCNNGenerator(adanet.subnetwork.Generator):\n",
        "  \"\"\"Generates a `SimpleCNN` at each iteration.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate, max_iteration_steps, seed=None):\n",
        "    \"\"\"Initializes a `Generator` that builds `SimpleCNNs`.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: The float learning rate to use.\n",
        "      max_iteration_steps: The number of steps per iteration.\n",
        "      seed: The random seed.\n",
        "\n",
        "    Returns:\n",
        "      An instance of `Generator`.\n",
        "    \"\"\"\n",
        "    self._seed = seed\n",
        "    self._dnn_builder_fn = functools.partial(\n",
        "        SimpleCNNBuilder,\n",
        "        learning_rate=learning_rate,\n",
        "        max_iteration_steps=max_iteration_steps)\n",
        "\n",
        "  def generate_candidates(self, previous_ensemble, iteration_number,\n",
        "                          previous_ensemble_reports, all_reports):\n",
        "    \"\"\"See `adanet.subnetwork.Generator`.\"\"\"\n",
        "    seed = self._seed\n",
        "    # Change the seed according to the iteration so that each subnetwork\n",
        "    # learns something different.\n",
        "    if seed is not None:\n",
        "      seed += iteration_number\n",
        "    return [self._dnn_builder_fn(seed=seed)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8sdvharsLJ1T"
      },
      "cell_type": "markdown",
      "source": [
        "With these defined, we pass them into a new `adanet.Estimator`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-Fhi1SjkzVBt",
        "outputId": "1de7b085-808e-4089-b627-8cb6414cbb36",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 3182
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Parameters\n",
        "LEARNING_RATE = 0.05  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "ADANET_ITERATIONS = 2  #@param {type:\"integer\"}\n",
        "\n",
        "max_iteration_steps = TRAIN_STEPS // ADANET_ITERATIONS\n",
        "estimator = adanet.Estimator(\n",
        "    head=head,\n",
        "    subnetwork_generator=SimpleCNNGenerator(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        max_iteration_steps=max_iteration_steps,\n",
        "        seed=RANDOM_SEED),\n",
        "    max_iteration_steps=max_iteration_steps,\n",
        "    evaluator=adanet.Evaluator(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    report_materializer=adanet.ReportMaterializer(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    adanet_loss_decay=.99,\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppowtPo\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd4b02e61d0>, '_model_dir': '/tmp/tmppowtPo', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 0\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppowtPo/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3571277, step = 0\n",
            "INFO:tensorflow:global_step/sec: 43.589\n",
            "INFO:tensorflow:loss = 0.24705152, step = 100 (2.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2107\n",
            "INFO:tensorflow:loss = 0.12670702, step = 200 (2.074 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.0113\n",
            "INFO:tensorflow:loss = 0.1341362, step = 300 (2.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2854\n",
            "INFO:tensorflow:loss = 0.070187554, step = 400 (2.071 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8873\n",
            "INFO:tensorflow:loss = 0.081513554, step = 500 (2.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9824\n",
            "INFO:tensorflow:loss = 0.009757163, step = 600 (2.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.1459\n",
            "INFO:tensorflow:loss = 0.042226065, step = 700 (2.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.0725\n",
            "INFO:tensorflow:loss = 0.03216999, step = 800 (2.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.3268\n",
            "INFO:tensorflow:loss = 0.013089663, step = 900 (2.069 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9334\n",
            "INFO:tensorflow:loss = 0.082337424, step = 1000 (2.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2168\n",
            "INFO:tensorflow:loss = 0.07295589, step = 1100 (2.073 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.3693\n",
            "INFO:tensorflow:loss = 0.018330155, step = 1200 (2.067 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.0704\n",
            "INFO:tensorflow:loss = 0.00275184, step = 1300 (2.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.015\n",
            "INFO:tensorflow:loss = 0.018656451, step = 1400 (2.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2162\n",
            "INFO:tensorflow:loss = 0.03235036, step = 1500 (2.074 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.1449\n",
            "INFO:tensorflow:loss = 0.05180301, step = 1600 (2.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.3484\n",
            "INFO:tensorflow:loss = 0.012016284, step = 1700 (2.068 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9704\n",
            "INFO:tensorflow:loss = 0.013398956, step = 1800 (2.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.1459\n",
            "INFO:tensorflow:loss = 0.012733309, step = 1900 (2.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.3828\n",
            "INFO:tensorflow:loss = 0.013341375, step = 2000 (2.067 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.0956\n",
            "INFO:tensorflow:loss = 0.025564319, step = 2100 (2.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9997\n",
            "INFO:tensorflow:loss = 0.016736845, step = 2200 (2.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2619\n",
            "INFO:tensorflow:loss = 0.06777242, step = 2300 (2.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.2462\n",
            "INFO:tensorflow:loss = 0.007885667, step = 2400 (2.073 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmppowtPo/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-23:28:14\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppowtPo/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'simple_cnn' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.987, accuracy/adanet/subnetwork = 0.987, accuracy/adanet/uniform_average_ensemble = 0.987, architecture/adanet/ensembles = \n",
            "\\\n",
            ":adanet/iteration_0/ensemble_simple_cnn/architecture/adanetB\u0014\b\u0007\u0012\u0000B\u000e| simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.042114854, average_loss/adanet/subnetwork = 0.042114854, average_loss/adanet/uniform_average_ensemble = 0.042114854, loss/adanet/adanet_weighted_ensemble = 0.041914545, loss/adanet/subnetwork = 0.041914545, loss/adanet/uniform_average_ensemble = 0.041914545\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-23:28:18\n",
            "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.987, accuracy/adanet/adanet_weighted_ensemble = 0.987, accuracy/adanet/subnetwork = 0.987, accuracy/adanet/uniform_average_ensemble = 0.987, average_loss = 0.042114854, average_loss/adanet/adanet_weighted_ensemble = 0.042114854, average_loss/adanet/subnetwork = 0.042114854, average_loss/adanet/uniform_average_ensemble = 0.042114854, global_step = 2500, loss = 0.041914545, loss/adanet/adanet_weighted_ensemble = 0.041914545, loss/adanet/subnetwork = 0.041914545, loss/adanet/uniform_average_ensemble = 0.041914545\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmppowtPo/model.ckpt-2500\n",
            "INFO:tensorflow:Loss for final step: 0.030540233.\n",
            "INFO:tensorflow:As the only candidate, 'simple_cnn' is moving onto the next iteration.\n",
            "INFO:tensorflow:Starting metric logging for iteration 0\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppowtPo/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Encountered end of input during report materialization\n",
            "INFO:tensorflow:Materialized subnetwork_reports.\n",
            "INFO:tensorflow:Wrote IterationReport for iteration 0 to /tmp/tmppowtPo/report/iteration_reports.tfrecord\n",
            "INFO:tensorflow:Finished saving subnetwork reports for iteration 0\n",
            "INFO:tensorflow:Freezing best ensemble to /tmp/tmppowtPo/frozen/ensemble-0.meta\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppowtPo/model.ckpt-2500\n",
            "INFO:tensorflow:Froze 7 variables.\n",
            "INFO:tensorflow:Converted 7 variables to const ops.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmppowtPo/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Overwriting checkpoint with new graph for iteration 1 to /tmp/tmppowtPo/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Finished training Adanet iteration 0\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmppowtPo/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppowtPo/increment.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmppowtPo/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.03190272, step = 2500\n",
            "INFO:tensorflow:global_step/sec: 38.9384\n",
            "INFO:tensorflow:loss = 0.004806356, step = 2600 (2.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8836\n",
            "INFO:tensorflow:loss = 0.0051763067, step = 2700 (2.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7675\n",
            "INFO:tensorflow:loss = 0.07183794, step = 2800 (2.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9556\n",
            "INFO:tensorflow:loss = 0.008811652, step = 2900 (2.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7677\n",
            "INFO:tensorflow:loss = 0.041897338, step = 3000 (2.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0104\n",
            "INFO:tensorflow:loss = 0.0014211655, step = 3100 (2.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9061\n",
            "INFO:tensorflow:loss = 0.009864207, step = 3200 (2.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8534\n",
            "INFO:tensorflow:loss = 0.0049079712, step = 3300 (2.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7421\n",
            "INFO:tensorflow:loss = 0.0069490606, step = 3400 (2.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8986\n",
            "INFO:tensorflow:loss = 0.021533731, step = 3500 (2.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9494\n",
            "INFO:tensorflow:loss = 0.022636488, step = 3600 (2.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1551\n",
            "INFO:tensorflow:loss = 0.004715823, step = 3700 (2.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9595\n",
            "INFO:tensorflow:loss = 0.0018476234, step = 3800 (2.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4979\n",
            "INFO:tensorflow:loss = 0.009362344, step = 3900 (2.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9882\n",
            "INFO:tensorflow:loss = 0.023754494, step = 4000 (2.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9748\n",
            "INFO:tensorflow:loss = 0.023741478, step = 4100 (2.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9926\n",
            "INFO:tensorflow:loss = 0.016029626, step = 4200 (2.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1079\n",
            "INFO:tensorflow:loss = 0.0120701855, step = 4300 (2.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8364\n",
            "INFO:tensorflow:loss = 0.0099483915, step = 4400 (2.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5442\n",
            "INFO:tensorflow:loss = 0.0125951655, step = 4500 (2.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8172\n",
            "INFO:tensorflow:loss = 0.016861422, step = 4600 (2.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1839\n",
            "INFO:tensorflow:loss = 0.014181782, step = 4700 (2.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.9635\n",
            "INFO:tensorflow:loss = 0.05990929, step = 4800 (2.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.067\n",
            "INFO:tensorflow:loss = 0.0070487554, step = 4900 (2.269 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmppowtPo/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmppowtPo/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-23:29:44\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppowtPo/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'previous_ensemble' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.987, accuracy/adanet/subnetwork = 0.987, accuracy/adanet/uniform_average_ensemble = 0.987, architecture/adanet/ensembles = \n",
            "N\n",
            ",adanet/previous_ensemble/architecture/adanetB\u0014\b\u0007\u0012\u0000B\u000e| simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.042114854, average_loss/adanet/subnetwork = 0.042114854, average_loss/adanet/uniform_average_ensemble = 0.042114854, loss/adanet/adanet_weighted_ensemble = 0.041914545, loss/adanet/subnetwork = 0.041914545, loss/adanet/uniform_average_ensemble = 0.041914545\n",
            "INFO:tensorflow:Saving candidate 'simple_cnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.9872, accuracy/adanet/subnetwork = 0.9857, accuracy/adanet/uniform_average_ensemble = 0.9872, architecture/adanet/ensembles = \n",
            "i\n",
            ":adanet/iteration_1/ensemble_simple_cnn/architecture/adanetB!\b\u0007\u0012\u0000B\u001b| simple_cnn | simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.039368387, average_loss/adanet/subnetwork = 0.044765316, average_loss/adanet/uniform_average_ensemble = 0.039368387, loss/adanet/adanet_weighted_ensemble = 0.039182022, loss/adanet/subnetwork = 0.044556204, loss/adanet/uniform_average_ensemble = 0.039182022\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-23:29:50\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9872, accuracy/adanet/adanet_weighted_ensemble = 0.9872, accuracy/adanet/subnetwork = 0.9857, accuracy/adanet/uniform_average_ensemble = 0.9872, average_loss = 0.039368387, average_loss/adanet/adanet_weighted_ensemble = 0.039368387, average_loss/adanet/subnetwork = 0.044765316, average_loss/adanet/uniform_average_ensemble = 0.039368387, global_step = 5000, loss = 0.039182022, loss/adanet/adanet_weighted_ensemble = 0.039182022, loss/adanet/subnetwork = 0.044556204, loss/adanet/uniform_average_ensemble = 0.039182022\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmppowtPo/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.022083024.\n",
            "Accuracy: 0.9872\n",
            "Loss: 0.039368387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3wGtI-4_LRw1"
      },
      "cell_type": "markdown",
      "source": [
        "Our `SimpleCNNGenerator` code achieves **90.41% accuracy**."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TKhCzP65hGyS"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion and next steps\n",
        "\n",
        "In this tutorial, you learned how to customize `adanet` to encode your\n",
        "understanding of a particular dataset, and explore novel search spaces with\n",
        "AdaNet.\n",
        "\n",
        "One use-case that has worked for us at Google, has been to take a production\n",
        "model's TensorFlow code, convert it to into an `adanet.subnetwork.Builder`, and\n",
        "adaptively grow it into an ensemble. In many cases, this has given significant\n",
        "performance improvements.\n",
        "\n",
        "As an exercise, you can swap out the FASHION-MNIST with the MNIST handwritten\n",
        "digits dataset in this notebook using `tf.keras.datasets.mnist.load_data()`, and\n",
        "see how `SimpleCNN` performs."
      ]
    }
  ]
}